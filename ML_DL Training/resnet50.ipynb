{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f799bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# PLANT DISEASE CLASSIFICATION - COMPLETE PIPELINE\n",
    "# TRAINING + EVALUATION + INFERENCE\n",
    "# =========================================================\n",
    "import os, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from datetime import datetime\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62f59cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CONFIGURATION\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\raw_work_minorproject\\disease_detection\\Classification\\disease_dataset1\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(BASE_DIR, \"valid\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"test\")\n",
    "RESULTS_DIR = \"evaluation_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"Resnet_50.pth\"\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c38d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# DATA TRANSFORMS\n",
    "# =========================================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7271ce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 38 plant disease classes.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# DATASETS & LOADERS\n",
    "# =========================================================\n",
    "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "val_ds   = datasets.ImageFolder(VAL_DIR, transform=test_transform)\n",
    "test_ds  = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "class_names = train_ds.classes\n",
    "print(f\"Detected {num_classes} plant disease classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bdb3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# MODEL SETUP (ResNet-50)\n",
    "# =========================================================\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Load pretrained model\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer for your number of classes\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3962da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Train Loss: 1.6750 | Val Loss: 0.8634 | Val Acc: 89.14%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 2/20\n",
      "Train Loss: 0.6392 | Val Loss: 0.4812 | Val Acc: 92.62%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 3/20\n",
      "Train Loss: 0.4205 | Val Loss: 0.3551 | Val Acc: 94.04%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 4/20\n",
      "Train Loss: 0.3239 | Val Loss: 0.2595 | Val Acc: 95.10%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 5/20\n",
      "Train Loss: 0.2713 | Val Loss: 0.2405 | Val Acc: 95.35%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 6/20\n",
      "Train Loss: 0.2372 | Val Loss: 0.1986 | Val Acc: 96.04%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 7/20\n",
      "Train Loss: 0.2129 | Val Loss: 0.1782 | Val Acc: 96.19%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 8/20\n",
      "Train Loss: 0.1975 | Val Loss: 0.1616 | Val Acc: 96.48%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 9/20\n",
      "Train Loss: 0.1819 | Val Loss: 0.1607 | Val Acc: 96.37%\n",
      "\n",
      "Epoch 10/20\n",
      "Train Loss: 0.1684 | Val Loss: 0.1350 | Val Acc: 96.65%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 11/20\n",
      "Train Loss: 0.1596 | Val Loss: 0.1307 | Val Acc: 96.89%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 12/20\n",
      "Train Loss: 0.1523 | Val Loss: 0.1339 | Val Acc: 96.99%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 13/20\n",
      "Train Loss: 0.1425 | Val Loss: 0.1241 | Val Acc: 96.94%\n",
      "\n",
      "Epoch 14/20\n",
      "Train Loss: 0.1405 | Val Loss: 0.1119 | Val Acc: 97.39%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 15/20\n",
      "Train Loss: 0.1333 | Val Loss: 0.1115 | Val Acc: 97.23%\n",
      "\n",
      "Epoch 16/20\n",
      "Train Loss: 0.1291 | Val Loss: 0.1125 | Val Acc: 97.45%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 17/20\n",
      "Train Loss: 0.1246 | Val Loss: 0.1102 | Val Acc: 97.32%\n",
      "\n",
      "Epoch 18/20\n",
      "Train Loss: 0.1204 | Val Loss: 0.1037 | Val Acc: 97.44%\n",
      "\n",
      "Epoch 19/20\n",
      "Train Loss: 0.1180 | Val Loss: 0.0958 | Val Acc: 97.62%\n",
      "✅ Best model saved!\n",
      "\n",
      "Epoch 20/20\n",
      "Train Loss: 0.1145 | Val Loss: 0.0955 | Val Acc: 97.61%\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# TRAINING LOOP\n",
    "# =========================================================\n",
    "best_val_acc = 0.0\n",
    "train_history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    train_history[\"train_loss\"].append(train_loss)\n",
    "    train_history[\"val_loss\"].append(val_loss)\n",
    "    train_history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(\"✅ Best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EVALUATION ON TEST SET\n",
    "# =========================================================\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a583a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total classes (train):\", len(class_names))\n",
    "print(\"Classes found in test predictions:\", len(set(all_labels)))\n",
    "print(\"Missing classes:\", set(range(len(class_names))) - set(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ed42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
